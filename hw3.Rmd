---
title: "p8105_hw3_yl2625"
author: "Yurou Liu"
date: "2025-10-07"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1
load in data

```{r}
library(dplyr)
library(p8105.datasets)

data("instacart") 
insta_ez_to_read = instacart %>% 
  select(aisle, everything())
```

### 1-1. How many aisles are there, and which aisles are the most items ordered from?

```{r}
# group by same aisles and sum up the order number for the same group 
total_aisle_df = insta_ez_to_read %>% 
  group_by(aisle) %>% 
  summarise(total_orders = n(), aisle = first(aisle)) %>%
  arrange(desc(total_orders))

# count the number of different aisles
num_aisles = n_distinct(total_aisle_df$aisle)

# find out the best seller
best_seller = total_aisle_df %>% 
  # pick out the aisle with the most orders, of there are aisles with the same number of orders, they will be picked out together
  filter(total_orders == max(total_orders))

print(num_aisles)
print(best_seller)
```
According to the printed results, there are 134 different aisles, and the most items are ordered from fresh vegetables, with 150609 orders in total.

### 1-2. make a plot

```{r, fig.height=16, fig.width=10}
plot_df = total_aisle_df %>% 
  filter(total_orders > 10000)

library(ggplot2)

plot_df %>% 
  ggplot(aes(y = reorder(aisle, total_orders), x = total_orders)) + 
  geom_col() +
  labs(title = "Aisles with 10000+ Orders", x = "Number of Orders", y = "Aisle") + 
  # add order number labels to the columns.
  geom_text(aes(label = format(total_orders, big.mark = ",")), hjust = -.05, size = 3) + 
  # expand x axis from the right side.
  scale_x_continuous(expand = expansion(mult = c(0, .1))) + 
  theme(plot.title = element_text(hjust = .5))
```

### 1-3. Table: three most popular items in 'baking ingredients', 'dog food care' and 'packaged vegetables fruits' with number of orders.

```{r}
df_for_table = insta_ez_to_read %>% 
  select(aisle, product_name) %>% 
  group_by(product_name) %>% 
  summarise(total_orders = n(), 
            aisle = first(aisle)) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits" )) %>% 
  group_by(aisle) %>% 
  slice_max(total_orders, n = 1) %>% 
  ungroup() %>% 
  select(aisle, everything()) %>% 
  print()
```

### 1-4. Table: mean hour of the day at which pink lady apples and coffee ice cream are ordered on each day of the week.

```{r}
library(tidyr)

df_for_table2 = insta_ez_to_read %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name) %>% 
  mutate(row_id = row_number()) %>% 
  pivot_wider(names_from = product_name, 
              values_from = order_hour_of_day) %>% 
  select(-row_id) %>% 
  arrange(order_dow) %>% 
  group_by(order_dow) %>% 
  summarise(mean_order_hour_apples = mean(`Pink Lady Apples`, na.rm = TRUE), 
         mean_order_hour_icecream = mean(`Coffee Ice Cream`, na.rm = TRUE)) %>% 
  mutate(order_dow = recode(order_dow, 
                            `0` = "Sunday", 
                            `1` = "Monday", 
                            `2` = "Tuesday", 
                            `3` = "Wednesday", 
                            `4` = "Thursday", 
                            `5` = "Friday", 
                            `6` = "Saturday")) %>% 
  print()
```


## Problem 2

```{r}
zillow_df = readr::read_csv("./data/zip_nyc.csv") %>% 
  janitor::clean_names()

a_zillow_df = zillow_df %>% 
  pivot_longer(c("x2015_01_31":"x2024_08_31"), 
               names_to = "date", 
               names_prefix = "x")

zip_count = a_zillow_df %>% 
  filter(!is.na(value)) %>%
  group_by(region_name) %>% 
  summarise(count = n())

```


### 2-1-a. How many ZIP codes are observed 116 times?

```{r}
obs_116_times = zip_count %>% 
  filter(count == 116) %>% 
  print()
```

According to the printed results, there are 48 zip codes that were observed 116 times in total.

### 2-1-b. How many are observed fewer than 10 times?

```{r}
obs_less_than_10 = zip_count %>% 
  filter(count < 10) %>% 
  print()
```

According to the printed results, there are 26 zip codes that were observed less than 10 times.

### 2-1-c. Why are some ZIP codes are observed rarely and others observed in each month?

According to a_zillow_df, differences in zip code observation times may due to the various data collection starting time. For example, 11368 was first observed from 2023-01-31, which may imply that the data collection in this area began later. Besides, there is also possibility that some zip codes were merged or split due to administrative changes, which can lead to the discontinuity and incomplete of these historical data.

### 2-2-a. Table: average rental price in wach borough and year. 

```{r}
queens_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Queens County") %>% 
  group_by(year) %>% 
  summarise(ave_rental_prices = mean(value, na.rm = TRUE))

kings_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Kings County") %>% 
  group_by(year) %>% 
  summarise(ave_rental_prices = mean(value, na.rm = TRUE))

richmond_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Richmond County") %>% 
  group_by(year) %>% 
  summarise(ave_rental_prices = mean(value, na.rm = TRUE))

bronx_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Bronx County") %>% 
  group_by(year) %>% 
  summarise(ave_rental_prices = mean(value, na.rm = TRUE))

ny_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "New York County") %>% 
  group_by(year) %>% 
  summarise(ave_rental_prices = mean(value, na.rm = TRUE))

p22a_df = bind_rows(
  queens_df %>% mutate(county = "Queens"), 
  kings_df %>% mutate(county = "Kings"), 
  richmond_df %>% mutate(county = "Richmond"),
  bronx_df %>% mutate(county = "Bronx"),
  ny_df %>% mutate(county = "New York")) %>% 
  pivot_wider(names_from = county, 
              values_from = ave_rental_prices) %>% 
  print()
```

### 2-2-b Comment on the table.

Overall speaking, all boroughs show an increase in rental prices from 2015 to 2024. The New York County stays the most expensive throughout the whole 10 years, followed by Kings, Queens, Richmond and Bronx. Rental prices in Queens and Kings County decreased from 2019 to 2021, rental prices in New York County decreased sharply from 2019 to 2020, probably due to the COVID-19 pandemic. While rental price in Richmond County increased from 2020 to 2024 and rental price of Bronx County kept increasing throughout the whole period observed.

### 2-3-a

```{r, fig.height=16, fig.width=20}
queens_23a_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Queens County") %>% 
  group_by(region_name, year) %>% 
  summarise(county = "Queens", ave_rental_prices = mean(value, na.rm = TRUE))

kings_23a_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Kings County") %>% 
  group_by(region_name, year) %>% 
  summarise(county = "Kings", ave_rental_prices = mean(value, na.rm = TRUE))

richmond_23a_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Richmond County") %>% 
  group_by(region_name, year) %>% 
  summarise(county = "Richmond", ave_rental_prices = mean(value, na.rm = TRUE))

bronx_23a_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "Bronx County") %>% 
  group_by(region_name, year) %>% 
  summarise(county = "Bronx", ave_rental_prices = mean(value, na.rm = TRUE))

ny_23a_df = a_zillow_df %>% 
  separate(date, c("year", "month","day")) %>% 
  filter(county_name == "New York County") %>% 
  group_by(region_name, year) %>% 
  summarise(county = "New York", ave_rental_prices = mean(value, na.rm = TRUE))

p23a_df = bind_rows(kings_23a_df, queens_23a_df, richmond_23a_df, bronx_23a_df, ny_23a_df)

p23a_plot = p23a_df %>% 
  ggplot(aes(x = year, y = ave_rental_prices, fill = as.factor(region_name))) +
  geom_col() + 
  facet_grid(. ~ county) + 
  scale_fill_viridis_d()
```